# Syst√®me RAG

Syst√®me **RAG** (Retrieval-Augmented Generation) pour interroger vos documents via une interface web, avec d√©ploiement Kubernetes, observabilit√© (Langfuse, MLflow) et CI/CD.

---

## Pr√©sentation de l'application

L'interface web permet d'**ajouter des documents** (PDF, DOCX, TXT) au syst√®me et de **poser des questions** pour obtenir des r√©ponses bas√©es sur leur contenu.

![Interface Syst√®me RAG ‚Äî Ajout de documents](images/Screenshot%20application.png)

- **Onglet ¬´ Ajouter des Documents ¬ª** : upload de fichiers (glisser-d√©poser ou s√©lection), formats support√©s PDF, DOCX, TXT.
- **Onglet ¬´ Poser une Question ¬ª** : saisie de la question, affichage de la r√©ponse, des sources et des scores d‚Äô√©valuation (automatique + notation manuelle).

---

## Fonctionnalit√©s

| Fonctionnalit√© | Description |
|----------------|-------------|
| **Ingestion** | Chargement et chunking de PDF, DOCX, TXT ; embeddings et stockage dans ChromaDB. |
| **Recherche** | Recherche par similarit√© dans le vector store, contexte envoy√© au LLM. |
| **G√©n√©ration** | R√©ponses g√©n√©r√©es via LangChain/LangGraph avec mod√®le configurable (OpenAI, etc.). |
| **Interface web** | Une seule page : upload de documents et questions/r√©ponses avec scores. |
| **√âvaluation** | Scores automatiques (pertinence, compl√©tude) et notation utilisateur (0‚Äì5 ou üëç/üëé) envoy√©e √† Langfuse. |
| **Observabilit√©** | Traces LLM et scores dans Langfuse ; m√©triques d‚Äôingestion dans MLflow. |
| **D√©ploiement** | Docker, Kubernetes (manifests dans `k8s/`), pipeline GitLab CI/CD. |

---

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Interface Web  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  API FastAPI ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  RAG Engine ‚îÇ
‚îÇ  (static/.)     ‚îÇ     ‚îÇ  (src/api)   ‚îÇ     ‚îÇ  LangGraph  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                        ‚îÇ                 ‚îÇ
         ‚îÇ                        ‚ñº                 ‚ñº
         ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ               ‚îÇ  Langfuse /  ‚îÇ   ‚îÇ  ChromaDB   ‚îÇ
         ‚îÇ               ‚îÇ  MLflow      ‚îÇ   ‚îÇ  (vecteurs) ‚îÇ
         ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
   Upload + Questions
```

- **RAG Engine** : LangChain + LangGraph (retrieval, g√©n√©ration).
- **API** : FastAPI (endpoints query, ingestion, sant√©, scoring Langfuse).
- **Vector Store** : ChromaDB (embeddings et recherche par similarit√©).
- **Monitoring** : Langfuse (traces, scores), MLflow (exp√©riences / ingestion), optionnel Prometheus/Grafana/Evidently.

---

## Structure du projet

```
rag_kube/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/           # FastAPI (main.py, routes)
‚îÇ   ‚îú‚îÄ‚îÄ rag/           # Pipeline RAG (ingestion, retrieval, generation, pipeline)
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/    # Evidently, Prometheus
‚îÇ   ‚îú‚îÄ‚îÄ utils/         # Langfuse scoring, MLflow REST
‚îÇ   ‚îî‚îÄ‚îÄ config.py      # Configuration (env)
‚îú‚îÄ‚îÄ static/            # Interface web (index.html)
‚îú‚îÄ‚îÄ scripts/           # Scripts CLI (upload, ask_question, start, etc.)
‚îú‚îÄ‚îÄ k8s/               # Manifests Kubernetes
‚îú‚îÄ‚îÄ docker/            # Prometheus, Grafana
‚îú‚îÄ‚îÄ docs/              # Documentation d√©taill√©e
‚îú‚îÄ‚îÄ images/            # Captures d‚Äô√©cran (ex. interface)
‚îú‚îÄ‚îÄ env.example        # Mod√®le de variables d‚Äôenvironnement
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ docker-compose.yml
```

---

## D√©marrage rapide

### Pr√©requis

- **Python 3.10+**
- Fichier **`.env`** configur√© (voir [Configuration](#-configuration))

### 1. Environnement et d√©pendances

```bash
# Environnement virtuel
python -m venv venv

# Activation
# Windows (PowerShell) :
.\venv\Scripts\Activate.ps1
# Linux / macOS :
source venv/bin/activate

# D√©pendances
pip install -r requirements.txt
```

### 2. Configuration

```bash
# Copier le mod√®le et √©diter avec vos cl√©s
cp env.example .env
```

Variables principales : `OPENAI_API_KEY`, `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, `LANGFUSE_HOST` (ex. `http://localhost:3000`), optionnel `MLFLOW_TRACKING_URI`. Voir `env.example` pour la liste compl√®te.

### 3. Lancer l‚ÄôAPI

**Via le script (recommand√©)**  
- Windows : `.\scripts\start.ps1`  
- Linux/macOS : `./scripts/start.sh`  

**Ou manuellement :**

```bash
uvicorn src.api.main:app --host 0.0.0.0 --port 8001 --reload
```

- **Interface web** : [http://localhost:8001](http://localhost:8001)  
- **Documentation API** : [http://localhost:8001/docs](http://localhost:8001/docs)  

> Si le port 8000 est bloqu√© sous Windows (erreur socket), le script utilise le port **8001**.

---

## Utilisation

1. **Ajouter des documents**  
   Onglet ¬´ Ajouter des Documents ¬ª ‚Üí choisir ou glisser-d√©poser des fichiers (PDF, DOCX, TXT) ‚Üí ¬´ Uploader le document ¬ª.

2. **Poser une question**  
   Onglet ¬´ Poser une Question ¬ª ‚Üí saisir la question ‚Üí envoyer. La r√©ponse, les sources et les scores s‚Äôaffichent.

3. **Noter une r√©ponse**  
   Utiliser les boutons üëç / üëé ou la note 0‚Äì5 et optionnellement un commentaire ; les notes sont envoy√©es √† Langfuse.

---

## Configuration

| Variable | Description |
|----------|-------------|
| `OPENAI_API_KEY` | Cl√© API OpenAI (ou autre provider selon le code). |
| `LANGFUSE_PUBLIC_KEY` / `LANGFUSE_SECRET_KEY` | Cl√©s Langfuse pour les traces et scores. |
| `LANGFUSE_HOST` | URL Langfuse (ex. `http://localhost:3000`). |
| `MLFLOW_TRACKING_URI` | URI du serveur MLflow (optionnel). |
| `CHROMA_PERSIST_DIR` | R√©pertoire de persistance ChromaDB (d√©faut : `./chroma_db`). |

D√©tails et exemples dans `env.example`.

---

## Monitoring et observabilit√©

| Service | URL type | R√¥le |
|---------|-----------|------|
| **Langfuse** | http://localhost:3000 | Traces LLM, scores (dont notation utilisateur). |
| **MLflow** | http://localhost:5000 | Suivi des exp√©riences et m√©triques d‚Äôingestion. |
| **Prometheus** | http://localhost:9090 | M√©triques (si d√©ploy√©). |
| **Grafana** | http://localhost:3001 | Dashboards (si d√©ploy√©). |

Voir `docs/LANGFUSE_SETUP.md`, `docs/MLFLOW_GUIDE.md` et `docs/` pour le d√©tail.

---

## D√©ploiement

- **Docker** : `docker-compose up -d` (voir `docker-compose.yml`).
- **Kubernetes** : `kubectl apply -f k8s/` puis v√©rifier les pods dans le namespace cible (ex. `rag-system`).

Le pipeline GitLab CI/CD (`.gitlab-ci.yml`) peut g√©rer build d‚Äôimages et d√©ploiement (ArgoCD/Flux selon configuration).

---

## Tests

```bash
pytest tests/
```

---

## Documentation

- **Interface web** : `README_WEB_INTERFACE.md`, `docs/HOW_TO_ADD_DOCUMENTS.md`
- **Langfuse** : `docs/LANGFUSE_SETUP.md`, `docs/LANGFUSE_SCORING.md`
- **MLflow** : `docs/MLFLOW_GUIDE.md`, `docs/MLFLOW_INTEGRATION.md`
- **D√©ploiement** : `docs/DEPLOYMENT.md`, `docs/ARCHITECTURE.md`
- **D√©pannage** : `docs/TROUBLESHOOTING_USER_RATING.md`, etc.

---

## Licence

MIT
